{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subset Selection - identifying which of the p predictors is most related to the response\n",
    "\n",
    "Shrinkage - helps reduce variation by shrinking coeffients towards zero.  Some coefficients may be shrunk to 0, so can have similar effects to Subset Selection.  Ridge Regression and Lasso.\n",
    "\n",
    "Dimension Reduction - project p predictors into M-dimensional subspace where M < p.  Find important combinations of variables.  PCR, Partial Least Squares\n",
    "\n",
    "\n",
    "Subset selection options:\n",
    "\n",
    "Best Subset selection - brute force building all models with 1, 2 ... p predictors and choosing the best model at k predictors.  Use RSS (Residual Sum of Squares) and R^2 to identify the error rate of the model.  Have to be careful choosing which k to use, because larger k values will always have equal or lower RSS.\n",
    "\n",
    "R^2 is proportion of variance explained by a linear regression model, least squares model\n",
    "\n",
    "6.1.2 Stepwise Selection\n",
    "Similar to best subset selection, but at each level we choose the best model from the previous level, rather than all models from the previous level.\n",
    "\n",
    "Hybrid stepwise selection\n",
    "Can remove variables that no longer provide improvement.\n",
    "\n",
    "6.1.3 Choosing the optimal model\n",
    "\n",
    "R^2 and RSS estimate training error, but don't estimate test error, we need other ways to measure test error.  We can reserve a subset of the training data as test (Ch. 5).  We can also adjust the training error to account for bias due to overfitting\n",
    "\n",
    "C_p, AIC (Akaike information criterion), BIC (Bayseian information criterion), Adjusted R^2\n",
    "\n",
    "For a fitted least squares model containing $d$ predictors, the $C_p$ estimate of test MSE is:\n",
    "\n",
    "$C_p = \\frac{1}{n}(RSS + 2d\\hat{\\sigma}^2)$\n",
    "\n",
    "Note: $\\sigma^2 = Var(X)$\n",
    "\n",
    "as $d$ increases, the penalty increases, to represent more likely overfitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [1] \"AtBat\"     \"Hits\"      \"HmRun\"     \"Runs\"      \"RBI\"       \"Walks\"    \n",
      " [7] \"Years\"     \"CAtBat\"    \"CHits\"     \"CHmRun\"    \"CRuns\"     \"CRBI\"     \n",
      "[13] \"CWalks\"    \"League\"    \"Division\"  \"PutOuts\"   \"Assists\"   \"Errors\"   \n",
      "[19] \"Salary\"    \"NewLeague\"\n"
     ]
    }
   ],
   "source": [
    "library(ISLR)\n",
    "# fix(Hitters)\n",
    "print(names(Hitters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in `colnames<-`(`*tmp*`, value = make.names(np)): attempt to set 'colnames' on an object with less than two dimensions\n",
     "output_type": "error",
     "traceback": [
      "Error in `colnames<-`(`*tmp*`, value = make.names(np)): attempt to set 'colnames' on an object with less than two dimensions\nTraceback:\n",
      "1. regsubsets(Y ~ ., data = data.full, nvmax = 10)",
      "2. regsubsets.formula(Y ~ ., data = data.full, nvmax = 10)",
      "3. leaps.setup(x, y, wt = wt, nbest = nbest, nvmax = nvmax, force.in = force.in, \n .     force.out = force.out, intercept = intercept)",
      "4. `colnames<-`(`*tmp*`, value = make.names(np))",
      "5. stop(\"attempt to set 'colnames' on an object with less than two dimensions\")"
     ]
    }
   ],
   "source": [
    "library(leaps)\n",
    "set.seed(1)\n",
    "X <- rnorm(100)\n",
    "noise <- rnorm(100)\n",
    "# b)                                                                                                                                \n",
    "Y <- 1+2*X+3*X^2+3*X^3+noise\n",
    "# X <- poly(X,10)\n",
    "# c)                                                                                                                                \n",
    "data.full <- data.frame(X, Y)\n",
    "regfit <- regsubsets(Y~.,data=data.full, nvmax=10)\n",
    "par(mfrow=c(2,2))\n",
    "plot(regfit, scale=\"adjr2\")\n",
    "plot(regfit, scale=\"Cp\")\n",
    "plot(regfit, scale=\"bic\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
